{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import datasets, metrics\n",
    "\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/Admin/School/eindopdracht/data/heart_train.parq'),\n",
       " WindowsPath('C:/Users/Admin/School/eindopdracht/data/heart_test.parq'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainfile = Path('../data/heart_train.parq').resolve()\n",
    "testfile = Path('../data/heart_test.parq').resolve()\n",
    "# trainfile = Path('../data/heart_big_train.parq').resolve()\n",
    "# testfile = Path('../data/heart_big_test.parq').resolve()\n",
    "trainfile, testfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets.HeartDataset2D(trainfile, target=\"target\")\n",
    "testdataset = datasets.HeartDataset2D(testfile, target=\"target\")\n",
    "traindataset, testdataset\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "traindataset.to(device)\n",
    "testdataset.to(device)\n",
    "trainstreamer = BaseDatastreamer(traindataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "teststreamer = BaseDatastreamer(testdataset, preprocessor = BasePreprocessor(), batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "import torch\n",
    "from filelock import FileLock\n",
    "from loguru import logger\n",
    "from mltrainer import ReportTypes, Trainer, TrainerSettings\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.search.bohb import TuneBOHB\n",
    "\n",
    "import models\n",
    "\n",
    "SAMPLE_INT = tune.search.sample.Integer\n",
    "SAMPLE_FLOAT = tune.search.sample.Float\n",
    "\n",
    "f1micro = metrics.F1Score(average='micro')\n",
    "f1macro = metrics.F1Score(average='macro')\n",
    "precision = metrics.Precision('micro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "def train(config: Dict):\n",
    "    \"\"\"\n",
    "    The train function should receive a config file, which is a Dict\n",
    "    ray will modify the values inside the config before it is passed to the train\n",
    "    function.\n",
    "\n",
    "    IMPORTANT: change model here if you want to actually use the transformer!\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.CNN(config) \n",
    "    model.to(device)\n",
    "\n",
    "    trainersettings = TrainerSettings(\n",
    "        epochs=10,\n",
    "        metrics=[accuracy],\n",
    "        logdir=\"heart2D\",\n",
    "        train_steps=len(trainstreamer),\n",
    "        valid_steps=len(teststreamer),  # type: ignore\n",
    "        reporttypes=[ReportTypes.RAY],\n",
    "        scheduler_kwargs={\"factor\": 0.2, \"patience\": 5},\n",
    "        earlystop_kwargs=None,\n",
    "    )\n",
    "\n",
    "    # because we set reporttypes=[ReportTypes.RAY]\n",
    "    # the trainloop wont try to report back to tensorboard,\n",
    "    # but will report back with ray\n",
    "    # this way, ray will know whats going on,\n",
    "    # and can start/pause/stop a loop.\n",
    "    # This is why we set earlystop_kwargs=None, because we\n",
    "    # are handing over this control to ray.\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=trainersettings,\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.Adam,  # type: ignore\n",
    "        traindataloader=trainstreamer.stream(),\n",
    "        validdataloader=teststreamer.stream(),\n",
    "        scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    )\n",
    "\n",
    "    trainer.loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code below executes ray. It asseses the search space\n",
    "using the configuration in config below.\n",
    "Changing the config = hypertune\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "tune_dir = Path(\"../../models/ray/\")\n",
    "tune_dir.exists(), tune_dir.resolve()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ray.init()\n",
    "    except:\n",
    "        ray.shutdown()\n",
    "        ray.init()\n",
    "\n",
    "    config = {\n",
    "        # \"input_size\": 1, irrelevant\n",
    "        \"num_classes\": 2,      #5 for big one\n",
    "        \"tune_dir\": tune_dir,\n",
    "        \"hidden\":  tune.randint(16, 128),\n",
    "        \"dropout\":  tune.uniform(0.1, 0.4),\n",
    "        \"num_layers\": tune.randint(2, 4),\n",
    "    }\n",
    "\n",
    "    reporter = CLIReporter()\n",
    "    reporter.add_metric_column(\"accuracy\")\n",
    "    reporter.add_metric_column(\"precision\")\n",
    "    reporter.add_metric_column(\"recall\")\n",
    "\n",
    "    bohb_hyperband = HyperBandForBOHB(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=50,\n",
    "        reduction_factor=3,\n",
    "        stop_last_trials=False,\n",
    "    )\n",
    "\n",
    "    bohb_search = TuneBOHB()\n",
    "\n",
    "    analysis = tune.run(\n",
    "        train,\n",
    "        config=config,\n",
    "        metric=\"test_loss\",\n",
    "        mode=\"min\",\n",
    "        progress_reporter=reporter,\n",
    "        # local_dir=str(config[\"tune_dir\"]),\n",
    "        num_samples=50,\n",
    "        search_alg=bohb_search,\n",
    "        scheduler=bohb_hyperband,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-30 12:42:39.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to heart2D\\20240130-124239\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [00:08<00:00, 41.32it/s]\n",
      "\u001b[32m2024-01-30 12:42:48.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 0 train 0.3724 test 0.2903 metric ['0.8799', '0.8799', '0.8526', '0.8799', '0.8739']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [00:09<00:00, 38.87it/s]\n",
      "\u001b[32m2024-01-30 12:42:58.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 1 train 0.2262 test 0.1794 metric ['0.9354', '0.9354', '0.9150', '0.9354', '0.9145']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [00:11<00:00, 32.07it/s]\n",
      "\u001b[32m2024-01-30 12:43:10.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 2 train 0.1472 test 0.1222 metric ['0.9576', '0.9576', '0.9455', '0.9576', '0.9495']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [00:29<00:00, 12.23it/s]\n",
      "\u001b[32m2024-01-30 12:43:43.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 3 train 0.1162 test 0.1222 metric ['0.9507', '0.9507', '0.9360', '0.9507', '0.9587']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:01<00:00,  5.93it/s]\n",
      "\u001b[32m2024-01-30 12:44:50.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 4 train 0.0923 test 0.0926 metric ['0.9705', '0.9705', '0.9619', '0.9705', '0.9655']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:13<00:00,  4.94it/s]\n",
      "\u001b[32m2024-01-30 12:46:11.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 5 train 0.0712 test 0.0667 metric ['0.9795', '0.9795', '0.9732', '0.9795', '0.9710']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:14<00:00,  4.91it/s]\n",
      "\u001b[32m2024-01-30 12:47:33.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 6 train 0.0642 test 0.0928 metric ['0.9649', '0.9649', '0.9545', '0.9649', '0.9573']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:14<00:00,  4.86it/s]\n",
      "\u001b[32m2024-01-30 12:48:55.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 7 train 0.0542 test 0.0817 metric ['0.9747', '0.9747', '0.9652', '0.9747', '0.9588']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:14<00:00,  4.88it/s]\n",
      "\u001b[32m2024-01-30 12:50:17.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 8 train 0.0464 test 0.0553 metric ['0.9812', '0.9812', '0.9753', '0.9812', '0.9791']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:14<00:00,  4.88it/s]\n",
      "\u001b[32m2024-01-30 12:51:40.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 9 train 0.0407 test 0.0757 metric ['0.9771', '0.9771', '0.9703', '0.9771', '0.9651']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:13<00:00,  4.91it/s]\n",
      "\u001b[32m2024-01-30 12:53:02.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 10 train 0.0354 test 0.0650 metric ['0.9792', '0.9792', '0.9749', '0.9792', '0.9790']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:15<00:00,  4.81it/s]\n",
      "\u001b[32m2024-01-30 12:54:25.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 11 train 0.0311 test 0.0476 metric ['0.9889', '0.9889', '0.9852', '0.9889', '0.9820']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:16<00:00,  4.75it/s]\n",
      "\u001b[32m2024-01-30 12:55:50.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 12 train 0.0234 test 0.0373 metric ['0.9892', '0.9892', '0.9848', '0.9892', '0.9831']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:18<00:00,  4.63it/s]\n",
      "\u001b[32m2024-01-30 12:57:17.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 13 train 0.0300 test 0.0756 metric ['0.9819', '0.9819', '0.9763', '0.9819', '0.9741']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:20<00:00,  4.52it/s]\n",
      "\u001b[32m2024-01-30 12:58:46.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 14 train 0.0229 test 0.0605 metric ['0.9788', '0.9788', '0.9723', '0.9788', '0.9785']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:19<00:00,  4.57it/s]\n",
      "\u001b[32m2024-01-30 13:00:15.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 15 train 0.0222 test 0.0693 metric ['0.9809', '0.9809', '0.9754', '0.9809', '0.9798']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:14<00:00,  4.90it/s]\n",
      "\u001b[32m2024-01-30 13:01:37.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 16 train 0.0220 test 0.0841 metric ['0.9837', '0.9837', '0.9778', '0.9837', '0.9744']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:10<00:00,  5.16it/s]\n",
      "\u001b[32m2024-01-30 13:02:55.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 17 train 0.0237 test 0.0567 metric ['0.9837', '0.9837', '0.9788', '0.9837', '0.9796']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:12<00:00,  4.98it/s]\n",
      "\u001b[32m2024-01-30 13:04:17.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 18 train 0.0131 test 0.0612 metric ['0.9889', '0.9889', '0.9848', '0.9889', '0.9859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:16<00:00,  4.76it/s]\n",
      "\u001b[32m2024-01-30 13:05:42.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 19 train 0.0186 test 0.0796 metric ['0.9785', '0.9785', '0.9717', '0.9785', '0.9739']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:20<00:00,  4.52it/s]\n",
      "\u001b[32m2024-01-30 13:07:12.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 20 train 0.0176 test 0.0642 metric ['0.9851', '0.9851', '0.9801', '0.9851', '0.9776']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:24<00:00,  4.27it/s]\n",
      "\u001b[32m2024-01-30 13:08:47.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 21 train 0.0134 test 0.0493 metric ['0.9885', '0.9885', '0.9850', '0.9885', '0.9819']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:24<00:00,  4.28it/s]\n",
      "\u001b[32m2024-01-30 13:10:23.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mEpoch 22 train 0.0212 test 0.0745 metric ['0.9840', '0.9840', '0.9778', '0.9840', '0.9754']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 363/363 [01:25<00:00,  4.24it/s]\n",
      " 77%|\u001b[38;2;30;71;6m███████▋  \u001b[0m| 23/30 [29:18<08:55, 76.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 23\u001b[0m\n\u001b[0;32m      4\u001b[0m settings \u001b[38;5;241m=\u001b[39m TrainerSettings(\n\u001b[0;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      6\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[accuracy, f1micro, f1macro, precision, recall],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     earlystop_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     16\u001b[0m     settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau\n\u001b[0;32m     22\u001b[0m     )\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\mltrainer\\trainer.py:84\u001b[0m, in \u001b[0;36mTrainer.loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mepochs), colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#1e4706\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     83\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainbatches()\n\u001b[1;32m---> 84\u001b[0m     metric_dict, test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevalbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(epoch, train_loss, test_loss, metric_dict)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\mltrainer\\trainer.py:126\u001b[0m, in \u001b[0;36mTrainer.evalbatches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(valid_steps):\n\u001b[0;32m    125\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvaliddataloader))\n\u001b[1;32m--> 126\u001b[0m     yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(yhat, y)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    128\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\src\\models.py:48\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvolutions:\n\u001b[1;32m---> 48\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(x)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\src\\models.py:18\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\School\\eindopdracht\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a way to manually run a model using a config of your choice.\n",
    "This is great to test the config I made with the hypertuning.\n",
    "\"\"\"\n",
    "\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=30,\n",
    "    metrics=[accuracy, f1micro, f1macro, precision, recall],\n",
    "    logdir=\"heart2D\",\n",
    "    train_steps=len(trainstreamer),\n",
    "    valid_steps=len(teststreamer),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    "    scheduler_kwargs={\"factor\": 0.2, \"patience\": 5},\n",
    "    earlystop_kwargs=None\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    traindataloader=trainstreamer.stream(),\n",
    "    validdataloader=teststreamer.stream(),\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    )\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 23.52222222222222, 'Predicted'),\n",
       " Text(50.722222222222214, 0.5, 'Target')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Precision + recall voor verslag:\n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "testdata = teststreamer.stream()\n",
    "for _ in range(len(teststreamer)):\n",
    "    X, y = next(testdata)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1) # we get the one with the highest probability\n",
    "    y_pred.append(yhat.cpu().tolist())\n",
    "    y_true.append(y.cpu().tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "# cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "\n",
    "plot = sns.heatmap(cfm, annot=cfm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
